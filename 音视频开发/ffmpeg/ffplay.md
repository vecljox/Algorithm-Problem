# 整体架构
- 初始化模块：完成参数解析、SDL 初始化、FFmpeg 初始化。
- 解复用模块：使用 FFmpeg 的 API 提取多媒体文件中的音频、视频和字幕流。
- 解码模块：对解复用得到的音视频帧进行解码。
- 同步模块：实现音视频同步，保持播放的流畅性。
- 渲染模块：将解码后的音频输出到声卡，视频通过 SDL2 渲染到窗口。
- 控制模块：处理用户输入（如暂停、跳转等操作）。

# 工作线程
ffplay 是一个多线程程序，主要的线程包括：
- 读取线程（read_thread）：读取媒体文件中的数据包。
- 解码线程：
  - 音频解码线程
  - 视频解码线程
  - 字幕解码线程（如果存在）
- 主线程：负责事件处理和渲染。

# 核心流程
1. 初始化
  - 使用 avformat_open_input() 打开多媒体文件。
  - 调用 avformat_find_stream_info() 获取流信息。
  - 初始化 SDL（包括音频和视频的输出环境）。
2. 解复用
  - 创建一个读取线程（read_thread），使用 av_read_frame() 循环读取媒体数据
  - 将读取到的音视频数据包分别放入队列（packet_queue）中
3. 解码
  - 对于每种流（音频、视频、字幕），启动一个解码线程。
  - 解码线程从对应的队列中取出数据包（AVPacket），调用解码函数（avcodec_receive_frame 和 avcodec_send_packet）解码为帧（AVFrame）。
  - 解码后的帧放入帧队列（frame_queue）中。
4. 同步
  - 使用音频时钟、视频时钟和外部时钟（系统时钟）进行同步,一般默认选择音频时钟作为主时钟。
  - 主要由音频驱动视频同步，确保播放流畅性。
5. 渲染
  - 音频：通过 SDL 音频子系统将解码后的音频数据送至声卡。
  - 视频：通过 SDL 视频子系统将解码后的图像帧显示在窗口中。

# 主要模块详细说明
#### （1）视频部分
- 视频解码使用 FFmpeg 的解码器完成，将 `AVPacket` 解码成 `AVFrame`。
- 使用 SDL 的 `SDL_Texture` 和 `SDL_Renderer` 渲染视频帧。
- 支持不同像素格式的转换（通常用 `sws_scale` 转换为 SDL 支持的格式）。

#### （2）音频部分
- 音频解码完成后，通过 SDL 音频回调函数将数据传输到声卡。
- 支持音频格式的重采样（`swr_convert`）。

#### （3）同步部分
- 维护音频时钟、视频时钟和外部时钟。
- 根据时钟的差异进行帧丢弃或等待，确保音视频同步。

#### （4）数据结构
- **`VideoState`**：核心结构体，管理音视频队列、解码器、帧队列等。
- **`PacketQueue`**：存储音视频数据包。
- **`FrameQueue`**：存储解码后的帧。

---
